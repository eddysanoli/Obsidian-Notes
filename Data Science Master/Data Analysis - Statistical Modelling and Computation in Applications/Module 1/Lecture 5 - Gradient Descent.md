
## 2. Convexity

- $A$ es positiva semi-definida cuando $v^TAv \geq 0$ o si ninguno de sus eigenvalores es negativo. 

![[Module 1 - Lecture 5 - Minimization of Loss Function]]

## 3. Multidimensional Convexity and Local Optimization

- A veces calcular una solución directa del gradiente igualado a 0 es muy difícil. En estos casos podemos utilizar optimización para llegar numéricamente a la solución
- Greedy local search
	- Empiezo en una posición arbitraria
	- En cada iteración me mueve en la dirección del progreso (local) 

![[Module 1 - Lecture 5 - Example Critical Point]]
![[Module 1 - Lecture 5 - Hessian Example]]


